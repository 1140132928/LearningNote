# 学习目标

+ 解决的问题
+ 使用的方法（原理核心）
+ 应用的场景

# 学习策略

**以用促学**：找一个小项目，自己动手写代码，然后不断去学习不懂的知识。纯粹任务驱动。

学习策略：（博客笔记时刻准备）

+ 初级：先快速把书籍过一遍，配合视频讲解，建立基本框架，对问题算法有直观理解，然后再翻阅数据，手动推理公式，实现代码。
+ 中级：比较各类算法的不同，适用场景。参加比赛和做项目，以用促学。
+ 高级：思考算法为什么这样推导，多问为什么?

## 较好的任务驱动平台

+ Kaggle：一个数据竞赛平台，有很多教程，项目，加深对算法理解。
+ [metacademy](https://metacademy.org/)：知识图谱，将知识依赖关系绘制出来，提供很好的入门学习指导。包括对应知识的优质学习资源。
+ [吴恩达机器学习](https://www.coursera.org/learn/machine-learning)：深入浅出的神课，包含许多课后作业，可手动实现
  + 课后习题实现：[python](https://github.com/nsoojin/coursera-ml-py)[|jupyter](https://github.com/kaleko/CourseraML)
+ [谷歌出品的机器学习课程](https://developers.google.com/machine-learning/crash-course)：快速入门，实例演练
+ 《机器学习入门实战》：python2实现算法

## 参考书

+ 李航《统计学习》：比较系统，成体系，适合作为框架，遇到不会的去翻《西瓜书》，更为具体
+ 周志华《西瓜书》：经典之作，更为具体，可配套《南瓜书》一块看，内含具体公式推导
+ 博客 / github 上他人整理好的笔记

[机器学习学习路线参考](https://www.zhihu.com/question/20691338?sort=created)

## 代码框架

+ [scikit-learn](https://scikit-learn.org/stable/)：文档写得和教程一样，值得研究

# 基本概念

机器学习就是利用输入和输出的样例，构建输入与输出的关系，利用此关系来预测新输入对应的输出。

可以类比线性代数等式 `Y=X`，其中 `X` 为输入，`Y` 为输出。以此我们引出以下几个术语：

+ `Labels`(标签)：就是输出的 `Y`（**只能有一个吗？**）
+ `Features`(特征)：就是输入的`X`，大写`X`通常表示向量，展开为`{x1,x2,...,xn}`

+ `Model`(模型)：就是`Y=F(x)` 中的函数关系，模型就是指输入和输出的关系（规律）。
  + 模型存在两个状态
    + `Training`：训练模型，根据样例数据找到输入和输出的关系
    + `Inference`：模型推理，应用已经训练得到的关系对新输入进行预测，得到输出
  + 根据输出的值类型分类（连续/离散）
    + `Regression`(回归)：预测输出的值是连续的（数不清楚）
      + 下个月百姓超市的苹果卖多少钱一斤？
      + 明天下雨概率是多少？
    + `Classification`(分类)：预测输出的值是离散的（数得清楚）
      + 图片里的是人，猫，狗？
      + 你是男人还是女人？

以上三个核心概念可看成抽象类，是一个壳/通式，需要实例化，于是出现了`Examples`

+ `Examples`(实例)：实例就是具体的数据，若类比数据库中表的概念，则`X和Y`是表头，那么`Examples`就是实际存在的数据。根据是否包含 `Labels` 分为两类：
  + `Labled example`：有标签数据，在**监督学习**中通常用于 `training` 阶段
  + `Unlabeld example`：无标签数据，非监督学习可用于 `training` ，其它均用于 `inference`

注意点

+ **特征选取**：特征要尽可能可量化，可观测。好的特征如长度，颜色，重量；不好特征的如美丽，漂亮这种主观性很强，不易量化和观测。

# 线性回归(Liner Regression)

类比数学中的直线拟合问题，直观来说，就是给定若干个点，然你找出一条直线，使得每个点到达直线的距离之和最小。那么直线的表示就两个要素，斜率和截距，斜截式如下：
$$
y=kx+b
$$
而在机器学习中，通常习惯把**斜率**叫做**权重** `weight`，**截距**叫做**偏移量** `bias`，因此直线表达式可写成以下形式：
$$
y=b+w_1x_1
$$
这是最简单的情况，可将变量(feature)扩展到n个，所以线性回归**通用表达式**如下：
$$
y=b+w_1x_1+w_2x_2+...+w_nx_n=b+\mathop{\Sigma}_\limits{i=1}^nx_i
$$
因此给出数学中常用术语和机器学习术语对照表：

| 数学术语  | 机器学习术语 |
| --------- | ------------ |
| 变量X     | 特征Feature  |
| 因变量Y   | 标签Label    |
| 函数关系F | 模型Model    |
| 直线斜率K | 特征权重W    |
| 直线截距b | 偏移量bias   |

模型的训练过程就是根据已知数据(examples)计算出表达式中的最优权值和偏移量。

那么如何计算最优呢？因此引入一个评价机制：损失函数 loss，来刻画估计值和真实值之间的偏差程度，该值越小说明估计值和真实值越接近，模型效果越好；反之说明效果差。

当模型训练到一定程度时即可将模型用于 Inference/Predicate 。loss过小会导致过拟合，即对新数据的预测能力很差；过大也是同样问题，因此选择合适的 loss 值，需要靠经验。

loss 函数有很多，最常见的是平方损失函数 Squared loss，即预测和实际值的差值的平方

```
Squared loss = (observation - predication(x))^2
```

对于所有样本则称作均方误差MSE(Mean Squared Error)，即每个样本的loss算术平均值
$$
MSE=\frac{1}{N}\sum\limits_{(x,y)\in D}(y-predication(x))^2
$$

+ N：是带标签的样本总个数
+ D：是数据集（样本集合）
+ (x,y)：是数据集的一个样本，x表示特征集合，y表示标签
+ predication表示模型（函数关系）

